{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30226be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "#import our data from balanced_filled_Dataset-vf.csv as data\n",
    "data = pd.read_csv('balanced_filled_Dataset-vf.csv')\n",
    "#split the data as 80% training and 20% testing\n",
    "X = data.iloc[:,0:14]\n",
    "Y = data.iloc[:,14]\n",
    "#scale the data\n",
    "scale_X = StandardScaler()\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, random_state = 777, test_size = 0.2)\n",
    "X_train = scale_X.fit_transform(X_train)\n",
    "X_test = scale_X.fit_transform(X_test)\n",
    "LogReg = LogisticRegression(random_state=20211008, max_iter=1000)\n",
    "LogReg.fit(X_train,Y_train)\n",
    "Y_predict = LogReg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a03c299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score (macro): 0.804738328187958\n",
      "f1_score (micro): 0.8019292604501608\n",
      "MCC: 0.7684790925247774\n",
      "Gmean: 0.883534047527952\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "\n",
    "\n",
    "f1_score_macro = f1_score(Y_test, Y_predict, average='macro')\n",
    "f1_score_micro = f1_score(Y_test, Y_predict, average='micro')\n",
    "MCC_score = matthews_corrcoef(Y_test, Y_predict)\n",
    "Gmean_score = geometric_mean_score(Y_test,Y_predict, average='macro')\n",
    "\n",
    "\n",
    "print(f'f1_score (macro): {f1_score_macro}')\n",
    "print(f'f1_score (micro): {f1_score_micro}')\n",
    "print(f'MCC: {MCC_score}')\n",
    "print(f'Gmean: {Gmean_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4722158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "data = pd.read_csv('balanced_filled_Dataset-vf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3db95e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X11</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>X14</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2892.0</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1889.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3208.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5394.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-740.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3245.0</td>\n",
       "      <td>97.630426</td>\n",
       "      <td>3.0</td>\n",
       "      <td>564.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>4387.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3157.0</td>\n",
       "      <td>307.000000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>2971.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>2467.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>637.0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3246.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4333.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>833.0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       X1          X2    X3     X4    X5      X6     X7     X8     X9     X10  \\\n",
       "0  2892.0   75.000000   7.0   95.0   9.0  1889.0  228.0  228.0  133.0  2371.0   \n",
       "1  3208.0    0.000000   9.0  124.0  -2.0  5394.0  206.0  222.0  154.0   900.0   \n",
       "2  3245.0   97.630426   3.0  564.0  66.0  4387.0  220.0  233.0  150.0  2650.0   \n",
       "3  3157.0  307.000000  27.0  120.0  35.0  2971.0  138.0  213.0  211.0  2467.0   \n",
       "4  3246.0   18.000000   9.0  120.0  11.0  4333.0  213.0  221.0  144.0   972.0   \n",
       "\n",
       "    X11    X12  X13  X14      Y  \n",
       "0  0.79   39.0    3   42  Apple  \n",
       "1  0.97 -740.0    1   42  Apple  \n",
       "2  0.55    4.0    1   42  Apple  \n",
       "3  0.19  637.0    1   44  Apple  \n",
       "4  0.93  833.0    1   59  Apple  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad29ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('Y', axis=1)\n",
    "Y = data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67bc312f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7774, 14), (7774,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a6ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size=0.8, random_state=20211008, stratify=Y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.8, random_state=20211008, \n",
    "                                                  stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88c47883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "penalty = ['l1', 'l2', 'elasticnet', None] # Specify the norm of the penalty\n",
    "class_weight = ['balanced', None] # Weights associated with classes in the form {class_label: weight}.\n",
    "solver = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'] # Algorithm to use in the optimization problem\n",
    "multi_class = ['auto', 'ovr', 'multinomial'] # Power parameter for the Minkowski metric. \n",
    "max_iter = [100, 1000, 10000]\n",
    "parameters = [penalty,class_weight,solver, multi_class, max_iter]  \n",
    "parameters_combinations = list(itertools.product(*parameters))\n",
    "len(parameters_combinations) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc07fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par = [x for x in parameters_combinations if x[0] != 'l1' and x[2] != 'lbfgs' ]\n",
    "par = [x for x in par if x[0] != 'elasticnet' and x[2] != 'lbfgs' ]\n",
    "\n",
    "\n",
    "par = [x for x in par if x[0] != 'elasticnet' and x[2] != 'liblinear' ]\n",
    "par = [x for x in par if x[0] != None and x[2] != 'liblinear' ]\n",
    "par = [x for x in par if x[3] != 'multinomial' and x[2] != 'liblinear' ]\n",
    "\n",
    "\n",
    "par = [x for x in par if x[0] != 'elasticnet' and x[2] != 'newton-cg' ]\n",
    "par = [x for x in par if x[0] != 'l1' and x[2] != 'newton-cg' ]\n",
    "\n",
    "par = [x for x in par if x[0] != 'elasticnet' and x[2] != 'sag' ]\n",
    "par = [x for x in par if x[0] != 'l1' and x[2] != 'sag' ]\n",
    "\n",
    "len(par)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b12495d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('l2', 'balanced', 'newton-cholesky', 'auto', 100),\n",
       " ('l2', 'balanced', 'newton-cholesky', 'auto', 1000),\n",
       " ('l2', 'balanced', 'newton-cholesky', 'auto', 10000),\n",
       " ('l2', 'balanced', 'newton-cholesky', 'ovr', 100),\n",
       " ('l2', 'balanced', 'newton-cholesky', 'ovr', 1000),\n",
       " ('l2', 'balanced', 'newton-cholesky', 'ovr', 10000),\n",
       " ('l2', 'balanced', 'saga', 'auto', 100),\n",
       " ('l2', 'balanced', 'saga', 'auto', 1000),\n",
       " ('l2', 'balanced', 'saga', 'auto', 10000),\n",
       " ('l2', 'balanced', 'saga', 'ovr', 100),\n",
       " ('l2', 'balanced', 'saga', 'ovr', 1000),\n",
       " ('l2', 'balanced', 'saga', 'ovr', 10000),\n",
       " ('l2', None, 'newton-cholesky', 'auto', 100),\n",
       " ('l2', None, 'newton-cholesky', 'auto', 1000),\n",
       " ('l2', None, 'newton-cholesky', 'auto', 10000),\n",
       " ('l2', None, 'newton-cholesky', 'ovr', 100),\n",
       " ('l2', None, 'newton-cholesky', 'ovr', 1000),\n",
       " ('l2', None, 'newton-cholesky', 'ovr', 10000),\n",
       " ('l2', None, 'saga', 'auto', 100),\n",
       " ('l2', None, 'saga', 'auto', 1000),\n",
       " ('l2', None, 'saga', 'auto', 10000),\n",
       " ('l2', None, 'saga', 'ovr', 100),\n",
       " ('l2', None, 'saga', 'ovr', 1000),\n",
       " ('l2', None, 'saga', 'ovr', 10000)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a79db36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b9667c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: auto, max iter: 100\n",
      "accuracy: 0.7235360450790888\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: auto, max iter: 1000\n",
      "accuracy: 0.7235360450790888\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: auto, max iter: 10000\n",
      "accuracy: 0.7235360450790888\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: ovr, max iter: 100\n",
      "accuracy: 0.7235360450790888\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: ovr, max iter: 1000\n",
      "accuracy: 0.7235360450790888\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: ovr, max iter: 10000\n",
      "accuracy: 0.7235360450790888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: auto, max iter: 100\n",
      "accuracy: 0.8126074701493602\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: auto, max iter: 1000\n",
      "accuracy: 0.8126074701493602\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: auto, max iter: 10000\n",
      "accuracy: 0.8126074701493602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: ovr, max iter: 100\n",
      "accuracy: 0.7235131873239029\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: ovr, max iter: 1000\n",
      "accuracy: 0.7235131873239029\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: ovr, max iter: 10000\n",
      "accuracy: 0.7235131873239029\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: auto, max iter: 100\n",
      "accuracy: 0.7360968671338137\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: auto, max iter: 1000\n",
      "accuracy: 0.7360968671338137\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: auto, max iter: 10000\n",
      "accuracy: 0.7360968671338137\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: ovr, max iter: 100\n",
      "accuracy: 0.7360968671338137\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: ovr, max iter: 1000\n",
      "accuracy: 0.7360968671338137\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: ovr, max iter: 10000\n",
      "accuracy: 0.7360968671338137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: auto, max iter: 100\n",
      "accuracy: 0.808862310101704\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: auto, max iter: 1000\n",
      "accuracy: 0.808862310101704\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: auto, max iter: 10000\n",
      "accuracy: 0.808862310101704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: ovr, max iter: 100\n",
      "accuracy: 0.7360968671338137\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: ovr, max iter: 1000\n",
      "accuracy: 0.7360968671338137\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: ovr, max iter: 10000\n",
      "accuracy: 0.7360968671338137\n"
     ]
    }
   ],
   "source": [
    "best_acc_params = {\"penalty\": None, \"class_weight\": None, \"solver\": None,\n",
    "                         \"multi_class\": None,\"max_iter\": 0, \"accuracy\": {\n",
    "                             \"average_score\": 0,\n",
    "                             \"f1_score_macro\": 0,\n",
    "                             \"f1_score_micro\": 0,\n",
    "                             \"MCC\": 0,\n",
    "                             \"Gmean\": 0\n",
    "                         }}\n",
    "\n",
    "for params in par:\n",
    "    \n",
    "    classifer = make_pipeline(StandardScaler(), LogisticRegression(penalty=params[0], class_weight=params[1], \n",
    "                                                                       solver=params[2], multi_class=params[3], \n",
    "                                                                  max_iter=params[4]))\n",
    "    classifer = classifer.fit(X_train,y_train)\n",
    "    y_pred = classifer.predict(X_val)\n",
    "\n",
    "\n",
    "    f1_score_macro = f1_score(y_val, y_pred, average='macro')\n",
    "    f1_score_micro = f1_score(y_val, y_pred, average='micro')\n",
    "    MCC_score = matthews_corrcoef(y_val, y_pred)\n",
    "    Gmean_score = geometric_mean_score(y_val,y_pred, average='macro')\n",
    "    accuracy = (f1_score_macro + f1_score_micro + MCC_score + Gmean_score) / 4.0\n",
    "\n",
    "    if accuracy > 0.50:\n",
    "        print(f'parameters: \\n penalty: {params[0]}, class_weight: {params[1]}, solver: {params[2]}, multi_class: {params[3]}, max iter: {params[4]}')\n",
    "        print(f'accuracy: {accuracy}')\n",
    "        if accuracy > best_acc_params['accuracy']['average_score']:\n",
    "            best_acc_params.update({\"penalty\": params[0], \"class_weight\": params[1], \"solver\": params[2],\n",
    "                         \"multi_class\": params[3], \"max_iter\": params[4],\"accuracy\": {\n",
    "                             \"average_score\": accuracy,\n",
    "                             \"f1_score_macro\": f1_score_macro,\n",
    "                             \"f1_score_micro\": f1_score_micro,\n",
    "                             \"MCC\": MCC_score,\n",
    "                             \"Gmean\": Gmean_score\n",
    "                         }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a14304f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2',\n",
       " 'class_weight': 'balanced',\n",
       " 'solver': 'saga',\n",
       " 'multi_class': 'auto',\n",
       " 'max_iter': 100,\n",
       " 'accuracy': {'average_score': 0.8126074701493602,\n",
       "  'f1_score_macro': 0.8021036653327415,\n",
       "  'f1_score_micro': 0.7982315112540193,\n",
       "  'MCC': 0.7649347461006688,\n",
       "  'Gmean': 0.8851599579100118}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "142dbb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score (macro): 0.7965988205645658\n",
      "f1_score (micro): 0.7929260450160772\n",
      "MCC: 0.758928436842019\n",
      "Gmean: 0.8823439868178719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "LogisticClf= make_pipeline(StandardScaler(), LogisticRegression(penalty=best_acc_params['penalty'],\n",
    "                                                           class_weight=best_acc_params['class_weight'], \n",
    "                                                           solver=best_acc_params['solver'],\n",
    "                                                                multi_class=best_acc_params['multi_class'], \n",
    "                                                               max_iter=best_acc_params['max_iter']))\n",
    "LogisticClf = LogisticClf.fit(X_train,y_train)\n",
    "y_pred = LogisticClf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f1_score_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_score_micro = f1_score(y_test, y_pred, average='micro')\n",
    "MCC_score = matthews_corrcoef(y_test, y_pred)\n",
    "Gmean_score = geometric_mean_score(y_test,y_pred, average='macro')\n",
    "\n",
    "\n",
    "print(f'f1_score (macro): {f1_score_macro}')\n",
    "print(f'f1_score (micro): {f1_score_micro}')\n",
    "print(f'MCC: {MCC_score}')\n",
    "print(f'Gmean: {Gmean_score}')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "362c3e28a184c9a10a6611ff1607a8a63416bffb2ca322aa9e6df9bfad7a3e35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
