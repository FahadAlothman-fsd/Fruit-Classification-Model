{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4722158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41f08c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('processed_data/training_set.csv')\n",
    "testing_set = pd.read_csv('processed_data/testing_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a3db95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6417 entries, 0 to 6416\n",
      "Data columns (total 49 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0    FC11   6417 non-null   float64\n",
      " 1    FC12   6417 non-null   float64\n",
      " 2    FC13   6417 non-null   float64\n",
      " 3    FC14   6417 non-null   float64\n",
      " 4    CA21   6417 non-null   float64\n",
      " 5    CA22   6417 non-null   float64\n",
      " 6    CA23   6417 non-null   float64\n",
      " 7    CA24   6417 non-null   float64\n",
      " 8    CA25   6417 non-null   float64\n",
      " 9    CA26   6417 non-null   float64\n",
      " 10   CA30   6417 non-null   float64\n",
      " 11   CA31   6417 non-null   float64\n",
      " 12   CA32   6417 non-null   float64\n",
      " 13   CA33   6417 non-null   float64\n",
      " 14   CA34   6417 non-null   float64\n",
      " 15   CA36   6417 non-null   float64\n",
      " 16   CA37   6417 non-null   float64\n",
      " 17   CA38   6417 non-null   float64\n",
      " 18   CA39   6417 non-null   float64\n",
      " 19   CA40   6417 non-null   float64\n",
      " 20   CA41   6417 non-null   float64\n",
      " 21   CA42   6417 non-null   float64\n",
      " 22   CA43   6417 non-null   float64\n",
      " 23   CA44   6417 non-null   float64\n",
      " 24   CA46   6417 non-null   float64\n",
      " 25   CA48   6417 non-null   float64\n",
      " 26   CA49   6417 non-null   float64\n",
      " 27   CA50   6417 non-null   float64\n",
      " 28   CA51   6417 non-null   float64\n",
      " 29   CA52   6417 non-null   float64\n",
      " 30   CA53   6417 non-null   float64\n",
      " 31   CA54   6417 non-null   float64\n",
      " 32   CA55   6417 non-null   float64\n",
      " 33   CA58   6417 non-null   float64\n",
      " 34   CA59   6417 non-null   float64\n",
      " 35   CA60   6417 non-null   float64\n",
      " 36  X1      6417 non-null   float64\n",
      " 37  X2      6417 non-null   float64\n",
      " 38  X3      6417 non-null   float64\n",
      " 39  X4      6417 non-null   float64\n",
      " 40  X5      6417 non-null   float64\n",
      " 41  X6      6417 non-null   float64\n",
      " 42  X7      6417 non-null   float64\n",
      " 43  X8      6417 non-null   float64\n",
      " 44  X9      6417 non-null   float64\n",
      " 45  X10     6417 non-null   float64\n",
      " 46  X11     6417 non-null   float64\n",
      " 47  X12     6417 non-null   float64\n",
      " 48  Y       6417 non-null   object \n",
      "dtypes: float64(48), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "training_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21e8eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 957 entries, 0 to 956\n",
      "Data columns (total 49 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0    FC11   957 non-null    float64\n",
      " 1    FC12   957 non-null    float64\n",
      " 2    FC13   957 non-null    float64\n",
      " 3    FC14   957 non-null    float64\n",
      " 4    CA21   957 non-null    float64\n",
      " 5    CA22   957 non-null    float64\n",
      " 6    CA23   957 non-null    float64\n",
      " 7    CA24   957 non-null    float64\n",
      " 8    CA25   957 non-null    float64\n",
      " 9    CA26   957 non-null    float64\n",
      " 10   CA30   957 non-null    float64\n",
      " 11   CA31   957 non-null    float64\n",
      " 12   CA32   957 non-null    float64\n",
      " 13   CA33   957 non-null    float64\n",
      " 14   CA34   957 non-null    float64\n",
      " 15   CA36   957 non-null    float64\n",
      " 16   CA37   957 non-null    float64\n",
      " 17   CA38   957 non-null    float64\n",
      " 18   CA39   957 non-null    float64\n",
      " 19   CA40   957 non-null    float64\n",
      " 20   CA41   957 non-null    float64\n",
      " 21   CA42   957 non-null    float64\n",
      " 22   CA43   957 non-null    float64\n",
      " 23   CA44   957 non-null    float64\n",
      " 24   CA46   957 non-null    float64\n",
      " 25   CA48   957 non-null    float64\n",
      " 26   CA49   957 non-null    float64\n",
      " 27   CA50   957 non-null    float64\n",
      " 28   CA51   957 non-null    float64\n",
      " 29   CA52   957 non-null    float64\n",
      " 30   CA53   957 non-null    float64\n",
      " 31   CA54   957 non-null    float64\n",
      " 32   CA55   957 non-null    float64\n",
      " 33   CA58   957 non-null    float64\n",
      " 34   CA59   957 non-null    float64\n",
      " 35   CA60   957 non-null    float64\n",
      " 36  X1      957 non-null    float64\n",
      " 37  X2      957 non-null    float64\n",
      " 38  X3      957 non-null    float64\n",
      " 39  X4      957 non-null    float64\n",
      " 40  X5      957 non-null    float64\n",
      " 41  X6      957 non-null    float64\n",
      " 42  X7      957 non-null    float64\n",
      " 43  X8      957 non-null    float64\n",
      " 44  X9      957 non-null    float64\n",
      " 45  X10     957 non-null    float64\n",
      " 46  X11     957 non-null    float64\n",
      " 47  X12     957 non-null    float64\n",
      " 48  Y       957 non-null    object \n",
      "dtypes: float64(48), object(1)\n",
      "memory usage: 366.5+ KB\n"
     ]
    }
   ],
   "source": [
    "testing_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad29ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_set.drop('Y', axis=1)\n",
    "y_train = training_set['Y']\n",
    "X_test = testing_set.drop('Y', axis=1)\n",
    "y_test = testing_set['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67bc312f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6417, 48), (6417,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a6ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.8, random_state=20211008, \n",
    "                                                  stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88c47883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "penalty = ['l1', 'l2', 'elasticnet', None] # Specify the norm of the penalty\n",
    "class_weight = ['balanced', None] # Weights associated with classes in the form {class_label: weight}.\n",
    "solver = ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'] # Algorithm to use in the optimization problem\n",
    "multi_class = ['auto', 'ovr', 'multinomial'] # Power parameter for the Minkowski metric. \n",
    "max_iter = [100, 1000, 10000]\n",
    "parameters = [penalty,class_weight,solver, multi_class, max_iter]  \n",
    "parameters_combinations = list(itertools.product(*parameters))\n",
    "len(parameters_combinations) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bc07fc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par = [x for x in parameters_combinations if x[0] != 'l1' and x[2] != 'lbfgs' ]\n",
    "par = [x for x in par if x[0] != 'elasticnet' and x[2] != 'lbfgs' ]\n",
    "\n",
    "\n",
    "par = [x for x in par if x[0] != 'elasticnet' and x[2] != 'liblinear' ]\n",
    "par = [x for x in par if x[0] != None and x[2] != 'liblinear' ]\n",
    "par = [x for x in par if x[3] != 'multinomial' and x[2] != 'liblinear' ]\n",
    "\n",
    "\n",
    "par = [x for x in par if x[0] != 'elasticnet' and x[2] != 'newton-cg' ]\n",
    "par = [x for x in par if x[0] != 'l1' and x[2] != 'newton-cg' ]\n",
    "\n",
    "par = [x for x in par if x[0] != 'elasticnet' and x[2] != 'sag' ]\n",
    "par = [x for x in par if x[0] != 'l1' and x[2] != 'sag' ]\n",
    "\n",
    "len(par)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b12495d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('l2', 'balanced', 'newton-cholesky', 'auto', 100),\n",
       " ('l2', 'balanced', 'newton-cholesky', 'auto', 1000),\n",
       " ('l2', 'balanced', 'newton-cholesky', 'auto', 10000),\n",
       " ('l2', 'balanced', 'newton-cholesky', 'ovr', 100),\n",
       " ('l2', 'balanced', 'newton-cholesky', 'ovr', 1000),\n",
       " ('l2', 'balanced', 'newton-cholesky', 'ovr', 10000),\n",
       " ('l2', 'balanced', 'saga', 'auto', 100),\n",
       " ('l2', 'balanced', 'saga', 'auto', 1000),\n",
       " ('l2', 'balanced', 'saga', 'auto', 10000),\n",
       " ('l2', 'balanced', 'saga', 'ovr', 100),\n",
       " ('l2', 'balanced', 'saga', 'ovr', 1000),\n",
       " ('l2', 'balanced', 'saga', 'ovr', 10000),\n",
       " ('l2', None, 'newton-cholesky', 'auto', 100),\n",
       " ('l2', None, 'newton-cholesky', 'auto', 1000),\n",
       " ('l2', None, 'newton-cholesky', 'auto', 10000),\n",
       " ('l2', None, 'newton-cholesky', 'ovr', 100),\n",
       " ('l2', None, 'newton-cholesky', 'ovr', 1000),\n",
       " ('l2', None, 'newton-cholesky', 'ovr', 10000),\n",
       " ('l2', None, 'saga', 'auto', 100),\n",
       " ('l2', None, 'saga', 'auto', 1000),\n",
       " ('l2', None, 'saga', 'auto', 10000),\n",
       " ('l2', None, 'saga', 'ovr', 100),\n",
       " ('l2', None, 'saga', 'ovr', 1000),\n",
       " ('l2', None, 'saga', 'ovr', 10000)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a79db36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b9667c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: auto, max iter: 100\n",
      "accuracy: 0.8387768477461249\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: auto, max iter: 1000\n",
      "accuracy: 0.8387768477461249\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: auto, max iter: 10000\n",
      "accuracy: 0.8387768477461249\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: ovr, max iter: 100\n",
      "accuracy: 0.8387768477461249\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: ovr, max iter: 1000\n",
      "accuracy: 0.8387768477461249\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: newton-cholesky, multi_class: ovr, max iter: 10000\n",
      "accuracy: 0.8387768477461249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: auto, max iter: 100\n",
      "accuracy: 0.834704730334253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: auto, max iter: 1000\n",
      "accuracy: 0.8604431051507979\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: auto, max iter: 10000\n",
      "accuracy: 0.867542477418192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: ovr, max iter: 100\n",
      "accuracy: 0.8236141285911586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: ovr, max iter: 1000\n",
      "accuracy: 0.83887106474769\n",
      "parameters: \n",
      " penalty: l2, class_weight: balanced, solver: saga, multi_class: ovr, max iter: 10000\n",
      "accuracy: 0.8373415746511736\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: auto, max iter: 100\n",
      "accuracy: 0.8385098430145003\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: auto, max iter: 1000\n",
      "accuracy: 0.8385098430145003\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: auto, max iter: 10000\n",
      "accuracy: 0.8385098430145003\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: ovr, max iter: 100\n",
      "accuracy: 0.8385098430145003\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: ovr, max iter: 1000\n",
      "accuracy: 0.8385098430145003\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: newton-cholesky, multi_class: ovr, max iter: 10000\n",
      "accuracy: 0.8385098430145003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: auto, max iter: 100\n",
      "accuracy: 0.8389071296182876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: auto, max iter: 1000\n",
      "accuracy: 0.8683738230922426\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: auto, max iter: 10000\n",
      "accuracy: 0.872458416138608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: ovr, max iter: 100\n",
      "accuracy: 0.8194045281559458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: ovr, max iter: 1000\n",
      "accuracy: 0.8385798772417687\n",
      "parameters: \n",
      " penalty: l2, class_weight: None, solver: saga, multi_class: ovr, max iter: 10000\n",
      "accuracy: 0.840020540432788\n"
     ]
    }
   ],
   "source": [
    "best_acc_params = {\"penalty\": None, \"class_weight\": None, \"solver\": None,\n",
    "                         \"multi_class\": None,\"max_iter\": 0, \"accuracy\": {\n",
    "                             \"average_score\": 0,\n",
    "                             \"f1_score_macro\": 0,\n",
    "                             \"f1_score_micro\": 0,\n",
    "                             \"MCC\": 0,\n",
    "                             \"Gmean\": 0\n",
    "                         }}\n",
    "\n",
    "for params in par:\n",
    "    \n",
    "    classifer = make_pipeline(StandardScaler(), LogisticRegression(penalty=params[0], class_weight=params[1], \n",
    "                                                                       solver=params[2], multi_class=params[3], \n",
    "                                                                  max_iter=params[4]))\n",
    "    classifer = classifer.fit(X_train,y_train)\n",
    "    y_pred = classifer.predict(X_val)\n",
    "\n",
    "\n",
    "    f1_score_macro = f1_score(y_val, y_pred, average='macro')\n",
    "    f1_score_micro = f1_score(y_val, y_pred, average='micro')\n",
    "    MCC_score = matthews_corrcoef(y_val, y_pred)\n",
    "    Gmean_score = geometric_mean_score(y_val,y_pred, average='macro')\n",
    "    accuracy = (f1_score_macro + f1_score_micro + MCC_score + Gmean_score) / 4.0\n",
    "\n",
    "    if accuracy > 0.50:\n",
    "        print(f'parameters: \\n penalty: {params[0]}, class_weight: {params[1]}, solver: {params[2]}, multi_class: {params[3]}, max iter: {params[4]}')\n",
    "        print(f'accuracy: {accuracy}')\n",
    "        if accuracy > best_acc_params['accuracy']['average_score']:\n",
    "            best_acc_params.update({\"penalty\": params[0], \"class_weight\": params[1], \"solver\": params[2],\n",
    "                         \"multi_class\": params[3], \"max_iter\": params[4],\"accuracy\": {\n",
    "                             \"average_score\": accuracy,\n",
    "                             \"f1_score_macro\": f1_score_macro,\n",
    "                             \"f1_score_micro\": f1_score_micro,\n",
    "                             \"MCC\": MCC_score,\n",
    "                             \"Gmean\": Gmean_score\n",
    "                         }})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a14304f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'penalty': 'l2',\n",
       " 'class_weight': None,\n",
       " 'solver': 'saga',\n",
       " 'multi_class': 'auto',\n",
       " 'max_iter': 10000,\n",
       " 'accuracy': {'average_score': 0.872458416138608,\n",
       "  'f1_score_macro': 0.8663074124636888,\n",
       "  'f1_score_micro': 0.8621495327102804,\n",
       "  'MCC': 0.8386793354039379,\n",
       "  'Gmean': 0.9226973839765245}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "142dbb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score (macro): 0.742168414349916\n",
      "f1_score (micro): 0.8025078369905956\n",
      "MCC: 0.7539507171621728\n",
      "Gmean: 0.8853562616148319\n"
     ]
    }
   ],
   "source": [
    "LogisticClf= make_pipeline(StandardScaler(), LogisticRegression(penalty=best_acc_params['penalty'],\n",
    "                                                           class_weight=best_acc_params['class_weight'], \n",
    "                                                           solver=best_acc_params['solver'],\n",
    "                                                                multi_class=best_acc_params['multi_class'], \n",
    "                                                               max_iter=best_acc_params['max_iter']))\n",
    "LogisticClf = LogisticClf.fit(X_train,y_train)\n",
    "y_pred = LogisticClf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f1_score_macro = f1_score(y_test, y_pred, average='macro')\n",
    "f1_score_micro = f1_score(y_test, y_pred, average='micro')\n",
    "MCC_score = matthews_corrcoef(y_test, y_pred)\n",
    "Gmean_score = geometric_mean_score(y_test,y_pred, average='macro')\n",
    "\n",
    "\n",
    "print(f'f1_score (macro): {f1_score_macro}')\n",
    "print(f'f1_score (micro): {f1_score_micro}')\n",
    "print(f'MCC: {MCC_score}')\n",
    "print(f'Gmean: {Gmean_score}')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "362c3e28a184c9a10a6611ff1607a8a63416bffb2ca322aa9e6df9bfad7a3e35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
