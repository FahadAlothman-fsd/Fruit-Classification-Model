{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1921606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9af6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('processed_data/training_set.csv')\n",
    "testing_set = pd.read_csv('processed_data/testing_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e15e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6417 entries, 0 to 6416\n",
      "Data columns (total 49 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0    FC11   6417 non-null   float64\n",
      " 1    FC12   6417 non-null   float64\n",
      " 2    FC13   6417 non-null   float64\n",
      " 3    FC14   6417 non-null   float64\n",
      " 4    CA21   6417 non-null   float64\n",
      " 5    CA22   6417 non-null   float64\n",
      " 6    CA23   6417 non-null   float64\n",
      " 7    CA24   6417 non-null   float64\n",
      " 8    CA25   6417 non-null   float64\n",
      " 9    CA26   6417 non-null   float64\n",
      " 10   CA30   6417 non-null   float64\n",
      " 11   CA31   6417 non-null   float64\n",
      " 12   CA32   6417 non-null   float64\n",
      " 13   CA33   6417 non-null   float64\n",
      " 14   CA34   6417 non-null   float64\n",
      " 15   CA36   6417 non-null   float64\n",
      " 16   CA37   6417 non-null   float64\n",
      " 17   CA38   6417 non-null   float64\n",
      " 18   CA39   6417 non-null   float64\n",
      " 19   CA40   6417 non-null   float64\n",
      " 20   CA41   6417 non-null   float64\n",
      " 21   CA42   6417 non-null   float64\n",
      " 22   CA43   6417 non-null   float64\n",
      " 23   CA44   6417 non-null   float64\n",
      " 24   CA46   6417 non-null   float64\n",
      " 25   CA48   6417 non-null   float64\n",
      " 26   CA49   6417 non-null   float64\n",
      " 27   CA50   6417 non-null   float64\n",
      " 28   CA51   6417 non-null   float64\n",
      " 29   CA52   6417 non-null   float64\n",
      " 30   CA53   6417 non-null   float64\n",
      " 31   CA54   6417 non-null   float64\n",
      " 32   CA55   6417 non-null   float64\n",
      " 33   CA58   6417 non-null   float64\n",
      " 34   CA59   6417 non-null   float64\n",
      " 35   CA60   6417 non-null   float64\n",
      " 36  X1      6417 non-null   float64\n",
      " 37  X2      6417 non-null   float64\n",
      " 38  X3      6417 non-null   float64\n",
      " 39  X4      6417 non-null   float64\n",
      " 40  X5      6417 non-null   float64\n",
      " 41  X6      6417 non-null   float64\n",
      " 42  X7      6417 non-null   float64\n",
      " 43  X8      6417 non-null   float64\n",
      " 44  X9      6417 non-null   float64\n",
      " 45  X10     6417 non-null   float64\n",
      " 46  X11     6417 non-null   float64\n",
      " 47  X12     6417 non-null   float64\n",
      " 48  Y       6417 non-null   object \n",
      "dtypes: float64(48), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "training_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac4f22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 957 entries, 0 to 956\n",
      "Data columns (total 49 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0    FC11   957 non-null    float64\n",
      " 1    FC12   957 non-null    float64\n",
      " 2    FC13   957 non-null    float64\n",
      " 3    FC14   957 non-null    float64\n",
      " 4    CA21   957 non-null    float64\n",
      " 5    CA22   957 non-null    float64\n",
      " 6    CA23   957 non-null    float64\n",
      " 7    CA24   957 non-null    float64\n",
      " 8    CA25   957 non-null    float64\n",
      " 9    CA26   957 non-null    float64\n",
      " 10   CA30   957 non-null    float64\n",
      " 11   CA31   957 non-null    float64\n",
      " 12   CA32   957 non-null    float64\n",
      " 13   CA33   957 non-null    float64\n",
      " 14   CA34   957 non-null    float64\n",
      " 15   CA36   957 non-null    float64\n",
      " 16   CA37   957 non-null    float64\n",
      " 17   CA38   957 non-null    float64\n",
      " 18   CA39   957 non-null    float64\n",
      " 19   CA40   957 non-null    float64\n",
      " 20   CA41   957 non-null    float64\n",
      " 21   CA42   957 non-null    float64\n",
      " 22   CA43   957 non-null    float64\n",
      " 23   CA44   957 non-null    float64\n",
      " 24   CA46   957 non-null    float64\n",
      " 25   CA48   957 non-null    float64\n",
      " 26   CA49   957 non-null    float64\n",
      " 27   CA50   957 non-null    float64\n",
      " 28   CA51   957 non-null    float64\n",
      " 29   CA52   957 non-null    float64\n",
      " 30   CA53   957 non-null    float64\n",
      " 31   CA54   957 non-null    float64\n",
      " 32   CA55   957 non-null    float64\n",
      " 33   CA58   957 non-null    float64\n",
      " 34   CA59   957 non-null    float64\n",
      " 35   CA60   957 non-null    float64\n",
      " 36  X1      957 non-null    float64\n",
      " 37  X2      957 non-null    float64\n",
      " 38  X3      957 non-null    float64\n",
      " 39  X4      957 non-null    float64\n",
      " 40  X5      957 non-null    float64\n",
      " 41  X6      957 non-null    float64\n",
      " 42  X7      957 non-null    float64\n",
      " 43  X8      957 non-null    float64\n",
      " 44  X9      957 non-null    float64\n",
      " 45  X10     957 non-null    float64\n",
      " 46  X11     957 non-null    float64\n",
      " 47  X12     957 non-null    float64\n",
      " 48  Y       957 non-null    object \n",
      "dtypes: float64(48), object(1)\n",
      "memory usage: 366.5+ KB\n"
     ]
    }
   ],
   "source": [
    "testing_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288617bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_set.drop('Y', axis=1)\n",
    "y_train = training_set['Y']\n",
    "X_test = testing_set.drop('Y', axis=1)\n",
    "y_test = testing_set['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc3742e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6417, 48), (6417, 48))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e6242eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.8, random_state=20211008, \n",
    "                                                  stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6019a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "criterion = [\"gini\", \"entropy\"] # The function to measure the quality of a split. \n",
    "splitter = [\"best\", \"random\"] # The strategy used to choose the split at each node.\n",
    "max_depth = [None, 100, 1000] # The maximum depth of the tree.\n",
    "max_features = [None, \"auto\", \"sqrt\", \"log2\"] # The number of features to consider when looking for the best split   \n",
    "parameters = [criterion,splitter,max_depth, max_features]  \n",
    "parameters_combinations = list(itertools.product(*parameters))\n",
    "len(parameters_combinations) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84303db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from imblearn.metrics import geometric_mean_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c67227e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier: \n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: None, max features: None\n",
      "accuracy: 0.915367918710657\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: None, max features: None\n",
      "accuracy: 0.912081006928231\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: None, max features: auto\n",
      "accuracy: 0.8721869643489037\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: None, max features: auto\n",
      "accuracy: 0.8808863515426902\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: None, max features: sqrt\n",
      "accuracy: 0.8863786688444311\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: None, max features: sqrt\n",
      "accuracy: 0.8841231613446727\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: None, max features: log2\n",
      "accuracy: 0.850503747865873\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: None, max features: log2\n",
      "accuracy: 0.8609856233183893\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 100, max features: None\n",
      "accuracy: 0.9133098126253156\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 100, max features: None\n",
      "accuracy: 0.9162352224286241\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 100, max features: auto\n",
      "accuracy: 0.8779266575955066\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 100, max features: auto\n",
      "accuracy: 0.8742971252190994\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 100, max features: sqrt\n",
      "accuracy: 0.8730524539044535\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 100, max features: sqrt\n",
      "accuracy: 0.8806753133748432\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 100, max features: log2\n",
      "accuracy: 0.8869404460252958\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 100, max features: log2\n",
      "accuracy: 0.8637606642455242\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 1000, max features: None\n",
      "accuracy: 0.9141075627208091\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 1000, max features: None\n",
      "accuracy: 0.9131656535026116\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 1000, max features: auto\n",
      "accuracy: 0.8757634868454992\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 1000, max features: auto\n",
      "accuracy: 0.8672777598650582\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 1000, max features: sqrt\n",
      "accuracy: 0.8644718320670957\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 1000, max features: sqrt\n",
      "accuracy: 0.889400317515109\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 1000, max features: log2\n",
      "accuracy: 0.8533628490016302\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: best, max depth: 1000, max features: log2\n",
      "accuracy: 0.856472590301148\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: None, max features: None\n",
      "accuracy: 0.9180225701675218\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: None, max features: None\n",
      "accuracy: 0.9200432015030707\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: None, max features: auto\n",
      "accuracy: 0.8599090324450915\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: None, max features: auto\n",
      "accuracy: 0.8688339846247054\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: None, max features: sqrt\n",
      "accuracy: 0.8861470945197195\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: None, max features: sqrt\n",
      "accuracy: 0.8568550173937111\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: None, max features: log2\n",
      "accuracy: 0.8342256009309055\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: None, max features: log2\n",
      "accuracy: 0.8407077467610027\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 100, max features: None\n",
      "accuracy: 0.9177564437266645\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 100, max features: None\n",
      "accuracy: 0.9145307664675515\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 100, max features: auto\n",
      "accuracy: 0.8691232702254927\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 100, max features: auto\n",
      "accuracy: 0.850630564649579\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 100, max features: sqrt\n",
      "accuracy: 0.8704977233211165\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 100, max features: sqrt\n",
      "accuracy: 0.8512359795064113\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 100, max features: log2\n",
      "accuracy: 0.8443596068487985\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 100, max features: log2\n",
      "accuracy: 0.8602997842986294\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 1000, max features: None\n",
      "accuracy: 0.923234350356124\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 1000, max features: None\n",
      "accuracy: 0.9202425564196723\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 1000, max features: auto\n",
      "accuracy: 0.8203804278165123\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 1000, max features: auto\n",
      "accuracy: 0.8539383160904327\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 1000, max features: sqrt\n",
      "accuracy: 0.8586430126562344\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 1000, max features: sqrt\n",
      "accuracy: 0.8490172615064584\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 1000, max features: log2\n",
      "accuracy: 0.8665291872849789\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: gini, splitter: random, max depth: 1000, max features: log2\n",
      "accuracy: 0.8432716211273652\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: None, max features: None\n",
      "accuracy: 0.9154807311161063\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: None, max features: None\n",
      "accuracy: 0.9151700458842845\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: None, max features: auto\n",
      "accuracy: 0.8663320353103964\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: None, max features: auto\n",
      "accuracy: 0.8742759135459037\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: None, max features: sqrt\n",
      "accuracy: 0.8508101711340212\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: None, max features: sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8591030702248003\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: None, max features: log2\n",
      "accuracy: 0.8480678721275725\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: None, max features: log2\n",
      "accuracy: 0.8561866512003633\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 100, max features: None\n",
      "accuracy: 0.9122463458153777\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 100, max features: None\n",
      "accuracy: 0.9129645555128616\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 100, max features: auto\n",
      "accuracy: 0.8869622890821749\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 100, max features: auto\n",
      "accuracy: 0.8751430566080868\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 100, max features: sqrt\n",
      "accuracy: 0.8886337068648592\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 100, max features: sqrt\n",
      "accuracy: 0.8813735388751136\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 100, max features: log2\n",
      "accuracy: 0.8857963591730219\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 100, max features: log2\n",
      "accuracy: 0.8630459385666109\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 1000, max features: None\n",
      "accuracy: 0.9101948732908998\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 1000, max features: None\n",
      "accuracy: 0.9073236979990127\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 1000, max features: auto\n",
      "accuracy: 0.871079458052657\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 1000, max features: auto\n",
      "accuracy: 0.8956770370311788\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 1000, max features: sqrt\n",
      "accuracy: 0.8635499577176942\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 1000, max features: sqrt\n",
      "accuracy: 0.8700988359113204\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 1000, max features: log2\n",
      "accuracy: 0.8515620364818799\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: best, max depth: 1000, max features: log2\n",
      "accuracy: 0.8487013889730481\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: None, max features: None\n",
      "accuracy: 0.917006496060224\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: None, max features: None\n",
      "accuracy: 0.9218303609724372\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: None, max features: auto\n",
      "accuracy: 0.8611874128113647\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: None, max features: auto\n",
      "accuracy: 0.8641477216938954\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: None, max features: sqrt\n",
      "accuracy: 0.856628980246753\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: None, max features: sqrt\n",
      "accuracy: 0.8543741171667714\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: None, max features: log2\n",
      "accuracy: 0.8549011033321996\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: None, max features: log2\n",
      "accuracy: 0.851874868023949\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 100, max features: None\n",
      "accuracy: 0.9108207855830897\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 100, max features: None\n",
      "accuracy: 0.9099416679599623\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 100, max features: auto\n",
      "accuracy: 0.8671965391491855\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 100, max features: auto\n",
      "accuracy: 0.8651156900651282\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 100, max features: sqrt\n",
      "accuracy: 0.8609622740311026\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 100, max features: sqrt\n",
      "accuracy: 0.8671113735596083\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 100, max features: log2\n",
      "accuracy: 0.8706553774229682\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 100, max features: log2\n",
      "accuracy: 0.8521226963272583\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: None\n",
      "accuracy: 0.9005501505479137\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: None\n",
      "accuracy: 0.9215956830203396\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: auto\n",
      "accuracy: 0.8821997453459374\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: auto\n",
      "accuracy: 0.8663071183373353\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: sqrt\n",
      "accuracy: 0.8563914067082112\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: sqrt\n",
      "accuracy: 0.8491985993873463\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: log2\n",
      "accuracy: 0.8428779224144358\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: log2\n",
      "accuracy: 0.858071998888039\n",
      "--------------------------------------------------------------\n",
      "n_estimators: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: log2\n",
      "accuracy: 0.5081640436919224\n",
      "n_estimators: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: log2\n",
      "accuracy: 0.505929334354298\n",
      "n_estimators: 10\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: log2\n",
      "accuracy: 0.5136565338942272\n",
      "n_estimators: 10\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: log2\n",
      "accuracy: 0.6615488846476809\n",
      "n_estimators: 100\n",
      "parameters: \n",
      " criterion: entropy, splitter: random, max depth: 1000, max features: log2\n",
      "accuracy: 0.6154355057098635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# training and hyper-parameter tuning\n",
    "\n",
    "####### ADD YOUR CODE ####\n",
    "n_estimators_array = [10,100]\n",
    "best_acc_params = {\"base_estimator\": None, \"n_estimators\": None,\"accuracy\": 0}\n",
    "\n",
    "\n",
    "best_acc_params = {\"accuracy\": {\n",
    "                             \"average_score\": 0,\n",
    "                             \"f1_score_macro\": 0,\n",
    "                             \"f1_score_micro\": 0,\n",
    "                             \"MCC\": 0,\n",
    "                             \"Gmean\": 0\n",
    "                         }}\n",
    "print('Decision Tree Classifier: ')\n",
    "for params in parameters_combinations:\n",
    "    \n",
    "    des_tree_clf = DecisionTreeClassifier(criterion=params[0], splitter=params[1], \n",
    "                                          max_depth=params[2], max_features=params[3])\n",
    "    for n_estimators in n_estimators_array:\n",
    "        print(f'n_estimators: {n_estimators}')\n",
    "        clf = AdaBoostClassifier(estimator=des_tree_clf,n_estimators=n_estimators)\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        y_predict = clf.predict(X_val)\n",
    "\n",
    "        f1_score_macro = f1_score(y_val, y_predict, average='macro')\n",
    "        f1_score_micro = f1_score(y_val, y_predict, average='micro')\n",
    "        MCC_score = matthews_corrcoef(y_val, y_predict)\n",
    "        Gmean_score = geometric_mean_score(y_val,y_predict, average='macro')\n",
    "        accuracy = (f1_score_macro + f1_score_micro + MCC_score + Gmean_score) / 4.0\n",
    "        \n",
    "        if accuracy > 0.50:\n",
    "            print(f'parameters: \\n criterion: {params[0]}, splitter: {params[1]}, max depth: {params[2]}, max features: {params[3]}')\n",
    "            print(f'accuracy: {accuracy}')\n",
    "            if accuracy > best_acc_params['accuracy']['average_score']:\n",
    "                best_acc_params.update({\"base_estimator\": {\"name\": \"Decision Tree\", \"criterion\": params[0], \"splitter\": params[1], \"max_depth\": params[2],\n",
    "                         \"max_features\": params[3]}, \"n_estimators\": n_estimators,\"accuracy\": {\n",
    "                             \"average_score\": accuracy,\n",
    "                             \"f1_score_macro\": f1_score_macro,\n",
    "                             \"f1_score_micro\": f1_score_micro,\n",
    "                             \"MCC\": MCC_score,\n",
    "                             \"Gmean\": Gmean_score\n",
    "                         }})\n",
    "    print('--------------------------------------------------------------')\n",
    "    \n",
    "lr = LogisticRegression();\n",
    "bnb = BernoulliNB()\n",
    "gnb = GaussianNB()\n",
    "for base_est in [lr, bnb, gnb]:\n",
    "    for n_estimators in n_estimators_array:\n",
    "            print(f'n_estimators: {n_estimators}')\n",
    "            clf = AdaBoostClassifier(estimator=base_est,n_estimators=n_estimators)\n",
    "            clf = clf.fit(X_train, y_train)\n",
    "            y_predicts = clf.predict(X_val)\n",
    "\n",
    "            f1_score_macro = f1_score(y_val, y_predicts, average='macro')\n",
    "            f1_score_micro = f1_score(y_val, y_predicts, average='micro')\n",
    "            MCC_score = matthews_corrcoef(y_val, y_predicts)\n",
    "            Gmean_score = geometric_mean_score(y_val,y_predicts, average='macro')\n",
    "            accuracy = (f1_score_macro + f1_score_micro + MCC_score + Gmean_score) / 4.0\n",
    "\n",
    "            if accuracy > 0.50:\n",
    "                print(f'parameters: \\n criterion: {params[0]}, splitter: {params[1]}, max depth: {params[2]}, max features: {params[3]}')\n",
    "                print(f'accuracy: {accuracy}')\n",
    "                if accuracy > best_acc_params['accuracy']['average_score']:\n",
    "                    best_acc_params.update({\"base_estimator\": {\"name\": \"Decision Tree\", \"criterion\": params[0], \"splitter\": params[1], \"max_depth\": params[2],\n",
    "                             \"max_features\": params[3]}, \"n_estimators\": n_estimators,\"accuracy\": {\n",
    "                                 \"average_score\": accuracy,\n",
    "                                 \"f1_score_macro\": f1_score_macro,\n",
    "                                 \"f1_score_micro\": f1_score_micro,\n",
    "                                 \"MCC\": MCC_score,\n",
    "                                 \"Gmean\": Gmean_score\n",
    "                             }})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30a53bad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': {'average_score': 0.923234350356124,\n",
       "  'f1_score_macro': 0.9193915717691917,\n",
       "  'f1_score_micro': 0.9174454828660437,\n",
       "  'MCC': 0.9031066969083337,\n",
       "  'Gmean': 0.9529936498809273},\n",
       " 'base_estimator': {'name': 'Decision Tree',\n",
       "  'criterion': 'gini',\n",
       "  'splitter': 'random',\n",
       "  'max_depth': 1000,\n",
       "  'max_features': None},\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b72dec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score (macro): 0.7731738994425997\n",
      "f1_score (micro): 0.831765935214211\n",
      "MCC: 0.7905928118290567\n",
      "Gmean: 0.8926110891362069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ubi-A\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "base_estimator_params = best_acc_params['base_estimator']\n",
    "base_estimator = DecisionTreeClassifier(criterion=base_estimator_params['criterion'], \n",
    "                                                                         splitter=base_estimator_params['splitter'], \n",
    "                                                                         max_depth=base_estimator_params['max_depth'],\n",
    "                                                                         max_features=base_estimator_params['max_features'])\n",
    "clf = AdaBoostClassifier(estimator=base_estimator,n_estimators=best_acc_params['n_estimators'])\n",
    "clf = clf.fit(X_train, y_train)\n",
    "y_predicts = clf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f1_score_macro = f1_score(y_test, y_predicts, average='macro')\n",
    "f1_score_micro = f1_score(y_test, y_predicts, average='micro')\n",
    "MCC_score = matthews_corrcoef(y_test, y_predicts)\n",
    "Gmean_score = geometric_mean_score(y_test,y_predicts, average='macro')\n",
    "\n",
    "\n",
    "print(f'f1_score (macro): {f1_score_macro}')\n",
    "print(f'f1_score (micro): {f1_score_micro}')\n",
    "print(f'MCC: {MCC_score}')\n",
    "print(f'Gmean: {Gmean_score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
